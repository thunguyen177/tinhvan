<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <title>Articles on Machine learning techniques</title>
    <link rel="stylesheet" href="../css/style.css"/>
</head>
<body>
   <header>
        <div class="container">
            <h1> Ellie Nguyen </h1>
        </div>
    </header>

  <nav id="navbar">
      <div class="containerblue">
        <ul>
          <li><a href="../index.html"> Home</a> </li>
          <li> <a href="../ML%20and%20stat/index.html"> Statistics and Machine Learning</a> </li>
          <li> <a href="../programming/index.html">Programming</a> </li>
          <li> <a href="../vnm%20cul_his/index.html"> Vietnamese culture and history</a> </li>
        </ul>
      </div>
      <div class="containerpink">
        <ul>
          <li><a href="../index.html">Trang chủ</a>
          <li><a href="../Toi%20sang%20tac/index.html">Tác phẩm</a>
          <li><a href="../thong%20ke/khoa%20hoc%20du%20lieu.html">Khoa học dữ liệu</a> </li>
          <li><a href="../goc%20du%20hoc/index.html">Du học và ngoại ngữ</a> </li>
        </ul>
      </div>
  </nav>
    <div class = "searchbar">
        <script>
              (function() {
                var cx = '000342376851758299742:vxnvik3_5yc';
                var gcse = document.createElement('script');
                gcse.type = 'text/javascript';
                gcse.async = true;
                gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
                var s = document.getElementsByTagName('script')[0];
                s.parentNode.insertBefore(gcse, s);
              })();
        </script>
        <gcse:search></gcse:search>
    </div>

 <ul>
	<li><a href='https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding'>
On the Dimensionality of Word Embedding</a>. <a href='https://www.youtube.com/watch?v=DRdIlcOfhBo'>video</a>. 
<a href='https://github.com/ziyin-dl/word-embedding-dimensionality-selection'>source code</a>  

	<li><a href='https://papers.nips.cc/paper/7498-overfitting-or-perfect-fitting-risk-bounds-for-classification-and-regression-rules-that-interpolate'>
Overfitting or perfect fitting? Risk bounds for
classification and regression rules that interpolate</a> 

	<li> <a href='https://papers.nips.cc/paper/7343-removing-the-feature-correlation-effect-of-multiplicative-noise.pdf'>Removing the Feature Correlation Effect of
Multiplicative Noise</a>: The authors propose non-correlating
multiplicative noise, which exploits batch normalization to remove the
correlation effect. They show that it significantly
improves the performance of standard multiplicative noise on image classification
tasks, providing a better alternative to dropout for batch-normalized networks.
	
	<li><a href='https://papers.nips.cc/paper/7603-step-size-matters-in-deep-learning'>
Step Size Matters in Deep Learning</a> 
<li><a href='https://papers.nips.cc/paper/8007-neural-architecture-optimization'>Neural Architecture Optimization</a> 

</ul>
						<hr color = "#F333FF" width="400px">
						<h3> Machine Learning techniques </h3>
<ul>
	<li><a href='https://papers.nips.cc/paper/7562-when-do-random-forests-fail'>When do random forests fail?</a> 
</ul> 
						<hr color = "#F333FF" width="400px">
						<h3>Normalization & Regularization</h3>
<ul>
	<li><a href='https://papers.nips.cc/paper/7996-understanding-batch-normalization'>Understanding Batch Normalization</a> 
	<li> <a href = 'https://papers.nips.cc/paper/7321-algorithmic-regularization-in-learning-deep-homogeneous-models-layers-are-automatically-balanced.pdf'>
Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced˚.</a> 
<a href='https://www.youtube.com/watch?v=-hKAtCzAm_A'>video</a>

	<li><a href=''>How Does Batch Normalization Help Optimization?</a>, 
<a href='https://www.youtube.com/watch?v=ZOabsYbmBRM'>video</a> 

	<li><a href='https://papers.nips.cc/paper/7485-norm-matters-efficient-and-accurate-normalization-schemes-in-deep-networks'>
Norm matters: efficient and accurate normalization schemes in deep networks
</a>  <a href='https://www.youtube.com/watch?v=uFB_aBpMCRQ'>video</a>, 
<a href='https://github.com/eladhoffer/norm_matters'>source code</a>  

	<li><a href='https://papers.nips.cc/paper/7481-regularizing-by-the-variance-of-the-activations-sample-variances'>
Regularizing by the Variance of the Activations' Sample-Variances</a> 

</ul>

						<hr color = "#F333FF" width="400px"> 
						<h3>Optimization techniques </h3>
<ul>
	<li><a href='https://papers.nips.cc/paper/7461-distributed-stochastic-optimization-via-adaptive-sgd'>
Distributed Stochastic Optimization via Adaptive SGD</a> 

	<li><a href='https://papers.nips.cc/paper/7596-stochastic-spectral-and-conjugate-descent-methods'>
Stochastic Spectral and Conjugate Descent Methods</a> 
<li><a href='https://papers.nips.cc/paper/7834-exact-natural-gradient-in-deep-linear-networks-and-its-application-to-the-nonlinear-case'>
Exact natural gradient in deep linear networks and its application to the nonlinear case</a> 

	<li><a href='https://papers.nips.cc/paper/7560-optimization-over-continuous-and-multi-dimensional-decisions-with-observational-data'>
Optimization over Continuous and Multi-dimensional Decisions with Observational Data</a> 
	<li><a href='https://papers.nips.cc/paper/7621-escaping-saddle-points-in-constrained-optimization'>
Escaping Saddle Points in Constrained Optimization</a> 
	<li><a href='https://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization'>Adaptive Methods for Nonconvex Optimization</a>
	 
</ul> 

						<hr color = "#F333FF" width="400px"> 
						<h3> Small data and Sampling techniques </h3>
<ul>	
	<li><a href='https://papers.nips.cc/paper/7620-modern-neural-networks-generalize-on-small-data-sets'>
Modern Neural Networks Generalize on Small Data Sets</a> 
	<li><a href='https://papers.nips.cc/paper/7517-leveraged-volume-sampling-for-linear-regression'>
Leveraged volume sampling for linear regression</a> 
	<li><a href='https://papers.nips.cc/paper/7623-optimal-subsampling-with-influence-functions'>
Optimal Subsampling with Influence Functions</a> 
</ul>
    <!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5cf9633718532342"></script>
    <div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v3.3"></script>
<div class="fb-comments" data-href="https://ellienguyen.style/" data-width="" data-numposts="5"></div>
    <footer id="main-footer">
        <hr color = "black" width="400px">
            		Copyright &copy; 2019 Ellie Nguyen. All rights reserved.
	</footer>
</body>
</html>