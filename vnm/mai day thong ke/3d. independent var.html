<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>independent r.v.</title>
    <link rel="stylesheet" href="../../css/style.css"/>
    <script type="text/javascript" src="../../js/latexit.js"></script>
    <script type="text/javascript">
    LatexIT.add('p',true);
    </script>
</head>
<body>
<p>

    Hai biến ngẫu nhiên X và Y là độc lập khi và chỉ khi với các số a và b bất kỳ,
    biến cố $[X \le a]$ (biến cố rằng X nhỏ hơn hay bằng a) và $[Y \le b]$ là các biến cố độc lập.
<br>
    Tương tự, một tập hợp các biến ngẫu nhiên tùy ý là độc lập nếu với tập hợp hữu hạn bất kỳ
    $X_1,..., X_n$ và một tập hữu hạn bất kỳ gồm
    các số $a_1,..., a_n$, các biến cố $[X_1\le a_1],...,[X_n\le a_n]$  là các biến cố độc lập,
    như đã được định nghĩa ở trên.
<br>
<br>Nếu X và Y là độc lập, thì $E[X, Y] = E[X] E[Y]$ và $var(X + Y) = var(X) + var(Y)$.
    Do đó, $cov(X,Y) = 0$. Ta có thể hiểu trong trường hợp này là nếu X và Y là độc lập thì
    chúng không dao động cùng nhau, tức là $cov(X,Y) = 0$.
<br>
<br>Ngoài ra, các biến ngẫu nhiên X và Y với các hàm phân bố $F_X(x)$ và $F_Y(y)$,
    là độc lập khi và chỉ khi
    $F_{X,Y}(x,y)=F_{X}(x)F_{Y}(y), $
    <br>
    Giả sử $X,Y$  có hàm mật độ xác suất là $f_X(x)$ và $f_Y(y)$.
<br>$f_{X,Y}(x,y)=f_{X}(x)f_{Y}(y).$
    Để hiểu điều này, chúng ta cũng có thể liên tưởng đến việc hai biến cố $A,B$ là độc lập
    khi và chỉ khi
    $P(A\cap B)=P(A)P(B)$
<br>Nếu X và Y độc lập, thì hiệp phương sai của chúng bằng 0, bởi vì khi đó,
    $E(X. Y)=E(X). E(Y)=\mu \nu.$
<br>
<br>Thay thế vào dạng thứ hai của công thức hiệp phương sai ở trên, ta có
<br>
<br>$ Cov(X,Y)=\mu \nu -\mu \nu =0.$
<br>Tuy nhiên, điều ngược lại không đúng: <font color="red"> nếu X và Y có hiệp phương sai bằng 0,
    hai biến này KHÔNG nhất thiết độc lập</font>. Do đó, chúng ta có cái tên riêng cho mối quan hệ này:
    Các biến ngẫu nhiên có hiệp phương sai bằng không được gọi là
    <font color="green">không tương quan (uncorrelated)</font>.

</p>
</body>
</html>